{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tbot101/CIS-5190-Project/blob/main/Logistic_Regression_and_FFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "T9n9jAasn9ji",
        "outputId": "a800894a-9b2b-4332-b283-e1cc34d795f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%cd /content/drive/Shareddrives/CIS\\ 519\\ Final\\ Project"
      ],
      "metadata": {
        "id": "l92G2k-Oomhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e907a6e-a089-41ca-aa1d-6fbaab1c00a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/CIS 519 Final Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "# 'Reviews.csv' should be listed here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lYCwZ0Go1Pd",
        "outputId": "45c009e5-775f-4d11-dbbb-0510803c5457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'CIS 519 Project.ipynb'       'Project Milestone 2.gdoc'\n",
            " cleaned_reviews.csv          'Project Milestone 3.docx'\n",
            " fine-tuned-bert               \u001b[0m\u001b[01;34mres\u001b[0m/\n",
            " James_CIS_519_Project.ipynb   Reviews.csv\n",
            " \u001b[01;34mlogs4\u001b[0m/                       'Taha CIS 519 Project'\n",
            "'Project 1 Milestone.gdoc'    'Time-Shift CIS 519 Project'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "random.seed(42)\n"
      ],
      "metadata": {
        "id": "A9pUNAvYo-5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6c6a24-6181-4f71-86e5-dfa173d5c331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CLEANED = True"
      ],
      "metadata": {
        "id": "nOW6LZuOIBsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to use these parameters to read in some funky text\n",
        "if USE_CLEANED:\n",
        "  df = pd.read_csv('cleaned_reviews.csv', engine='python', on_bad_lines='skip')\n",
        "else:\n",
        "  df = pd.read_csv('Reviews.csv', engine='python', on_bad_lines='skip')\n",
        "  df['sentiment'] = df.apply(lambda x: 1 if x['Score'] > 3 else 0, axis=1)\n",
        "  df = df.sample(frac=0.2).reset_index(drop=True)\n",
        "  def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text)\n",
        "    lemma = WordNetLemmatizer()\n",
        "    result = [i for i in tokens if not i in stop_words]\n",
        "    lemmatized_result = []\n",
        "    for word in result:\n",
        "      lemmatized_result.append(lemma.lemmatize(word))\n",
        "\n",
        "    return \" \".join(lemmatized_result)\n",
        "  df['cleaned_text'] = df.apply(lambda x: preprocess_text(x['Text']), axis=1)"
      ],
      "metadata": {
        "id": "7TYQn2-Ho_sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "V3A4gSrNpB24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5ldLg7Q7I82F",
        "outputId": "16c57211-d0c9-4619-bc21-fb7525f6beac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0      Id   ProductId          UserId  \\\n",
              "0                0  119814  B0009YUEG2  A2F09EWKV3MTO2   \n",
              "1                1  290509  B004777F3M  A2PDNBEIQYRCT2   \n",
              "2                2  489194  B002N2R7WM  A1CHGDG3NUDA5R   \n",
              "3                3   65205  B001D0GV5O  A3GIKK6DQEKEQK   \n",
              "4                4  526585  B007PA30TG  A2XQSJG8YR6ED2   \n",
              "...            ...     ...         ...             ...   \n",
              "113686      113686   16241  B007TJGZ54  A1PLASEQUSPDPM   \n",
              "113687      113687  511398  B001E6J07I  A233H2J16V56W8   \n",
              "113688      113688  211139  B000X67P2C  A3G0H0GKJ0722I   \n",
              "113689      113689  520860  B0009XSXZM  A3FTHCRY3EZNA7   \n",
              "113690      113690  190700  B000FI4O90  A2XNFT83MTV6AN   \n",
              "\n",
              "                           ProfileName  HelpfulnessNumerator  \\\n",
              "0                          StillWaters                     4   \n",
              "1                               lmac60                     0   \n",
              "2       C. Seggelin \"Plastered Dragon\"                     0   \n",
              "3                  CHERYL A. CATANZANO                     0   \n",
              "4                           Cecilia f.                     0   \n",
              "...                                ...                   ...   \n",
              "113686                           Chris                     0   \n",
              "113687                     Claxon,Bill                     0   \n",
              "113688                        C. Smith                    10   \n",
              "113689                       categ3893                     1   \n",
              "113690               Randy Corder \"RC\"                     0   \n",
              "\n",
              "        HelpfulnessDenominator  Score        Time  \\\n",
              "0                            4      5  1303430400   \n",
              "1                            0      4  1309996800   \n",
              "2                            0      1  1350086400   \n",
              "3                            0      1  1296777600   \n",
              "4                            0      5  1303084800   \n",
              "...                        ...    ...         ...   \n",
              "113686                       0      5  1339718400   \n",
              "113687                       0      5  1237507200   \n",
              "113688                      13      1  1277164800   \n",
              "113689                       1      5  1333843200   \n",
              "113690                       0      4  1231286400   \n",
              "\n",
              "                                                  Summary  \\\n",
              "0                          This is all I ever use anymore   \n",
              "1                                               Good Tea!   \n",
              "2       Tasteless Fat For Your Popcorn!  Just Use Butter.   \n",
              "3                                              Very bland   \n",
              "4                                              great brew   \n",
              "...                                                   ...   \n",
              "113686                                     Price is Right   \n",
              "113687                                Tasty Carrs cracker   \n",
              "113688                                    Did not like...   \n",
              "113689              8 month Golden Retriever is OBSESSED.   \n",
              "113690                                         Aerogarden   \n",
              "\n",
              "                                                     Text  sentiment  \\\n",
              "0       I love this litter because...<br />1. It compl...          1   \n",
              "1       Great flavor.  Just enough spice.  A love Chai...          1   \n",
              "2       Y'know, you'd think with the words \"Buttery Fl...          0   \n",
              "3       I bought this tea because I like Timothy's Cof...          0   \n",
              "4       i've been using these k-cups for months now.  ...          1   \n",
              "...                                                   ...        ...   \n",
              "113686  Love the Green Mountain Coffee; tastes great i...          1   \n",
              "113687  A super glamourized cheez-it without the trans...          1   \n",
              "113688  I had heard so many good things about using th...          0   \n",
              "113689  My adolescent golden retriever just loves thes...          1   \n",
              "113690  Great product so far. The seeds are germinatin...          1   \n",
              "\n",
              "                                             cleaned_text  \n",
              "0       love litter br 1 completely eliminates urine o...  \n",
              "1       great flavor enough spice love chai tea latte ...  \n",
              "2       know think word buttery flavor product name pr...  \n",
              "3       bought tea like timothy coffee product figured...  \n",
              "4       using k cup month breakfast blend perfect peop...  \n",
              "...                                                   ...  \n",
              "113686  love green mountain coffee taste great keurig ...  \n",
              "113687  super glamourized cheez without trans fat chol...  \n",
              "113688  heard many good thing using place wheat white ...  \n",
              "113689  adolescent golden retriever love soon see hold...  \n",
              "113690  great product far seed germinating promised ea...  \n",
              "\n",
              "[113678 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e17ca78f-840e-41ca-a2ec-a19a1d824f86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>119814</td>\n",
              "      <td>B0009YUEG2</td>\n",
              "      <td>A2F09EWKV3MTO2</td>\n",
              "      <td>StillWaters</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1303430400</td>\n",
              "      <td>This is all I ever use anymore</td>\n",
              "      <td>I love this litter because...&lt;br /&gt;1. It compl...</td>\n",
              "      <td>1</td>\n",
              "      <td>love litter br 1 completely eliminates urine o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>290509</td>\n",
              "      <td>B004777F3M</td>\n",
              "      <td>A2PDNBEIQYRCT2</td>\n",
              "      <td>lmac60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1309996800</td>\n",
              "      <td>Good Tea!</td>\n",
              "      <td>Great flavor.  Just enough spice.  A love Chai...</td>\n",
              "      <td>1</td>\n",
              "      <td>great flavor enough spice love chai tea latte ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>489194</td>\n",
              "      <td>B002N2R7WM</td>\n",
              "      <td>A1CHGDG3NUDA5R</td>\n",
              "      <td>C. Seggelin \"Plastered Dragon\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1350086400</td>\n",
              "      <td>Tasteless Fat For Your Popcorn!  Just Use Butter.</td>\n",
              "      <td>Y'know, you'd think with the words \"Buttery Fl...</td>\n",
              "      <td>0</td>\n",
              "      <td>know think word buttery flavor product name pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>65205</td>\n",
              "      <td>B001D0GV5O</td>\n",
              "      <td>A3GIKK6DQEKEQK</td>\n",
              "      <td>CHERYL A. CATANZANO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1296777600</td>\n",
              "      <td>Very bland</td>\n",
              "      <td>I bought this tea because I like Timothy's Cof...</td>\n",
              "      <td>0</td>\n",
              "      <td>bought tea like timothy coffee product figured...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>526585</td>\n",
              "      <td>B007PA30TG</td>\n",
              "      <td>A2XQSJG8YR6ED2</td>\n",
              "      <td>Cecilia f.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1303084800</td>\n",
              "      <td>great brew</td>\n",
              "      <td>i've been using these k-cups for months now.  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>using k cup month breakfast blend perfect peop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113686</th>\n",
              "      <td>113686</td>\n",
              "      <td>16241</td>\n",
              "      <td>B007TJGZ54</td>\n",
              "      <td>A1PLASEQUSPDPM</td>\n",
              "      <td>Chris</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1339718400</td>\n",
              "      <td>Price is Right</td>\n",
              "      <td>Love the Green Mountain Coffee; tastes great i...</td>\n",
              "      <td>1</td>\n",
              "      <td>love green mountain coffee taste great keurig ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113687</th>\n",
              "      <td>113687</td>\n",
              "      <td>511398</td>\n",
              "      <td>B001E6J07I</td>\n",
              "      <td>A233H2J16V56W8</td>\n",
              "      <td>Claxon,Bill</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1237507200</td>\n",
              "      <td>Tasty Carrs cracker</td>\n",
              "      <td>A super glamourized cheez-it without the trans...</td>\n",
              "      <td>1</td>\n",
              "      <td>super glamourized cheez without trans fat chol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113688</th>\n",
              "      <td>113688</td>\n",
              "      <td>211139</td>\n",
              "      <td>B000X67P2C</td>\n",
              "      <td>A3G0H0GKJ0722I</td>\n",
              "      <td>C. Smith</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1277164800</td>\n",
              "      <td>Did not like...</td>\n",
              "      <td>I had heard so many good things about using th...</td>\n",
              "      <td>0</td>\n",
              "      <td>heard many good thing using place wheat white ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113689</th>\n",
              "      <td>113689</td>\n",
              "      <td>520860</td>\n",
              "      <td>B0009XSXZM</td>\n",
              "      <td>A3FTHCRY3EZNA7</td>\n",
              "      <td>categ3893</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1333843200</td>\n",
              "      <td>8 month Golden Retriever is OBSESSED.</td>\n",
              "      <td>My adolescent golden retriever just loves thes...</td>\n",
              "      <td>1</td>\n",
              "      <td>adolescent golden retriever love soon see hold...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113690</th>\n",
              "      <td>113690</td>\n",
              "      <td>190700</td>\n",
              "      <td>B000FI4O90</td>\n",
              "      <td>A2XNFT83MTV6AN</td>\n",
              "      <td>Randy Corder \"RC\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1231286400</td>\n",
              "      <td>Aerogarden</td>\n",
              "      <td>Great product so far. The seeds are germinatin...</td>\n",
              "      <td>1</td>\n",
              "      <td>great product far seed germinating promised ea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>113678 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e17ca78f-840e-41ca-a2ec-a19a1d824f86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e17ca78f-840e-41ca-a2ec-a19a1d824f86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e17ca78f-840e-41ca-a2ec-a19a1d824f86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "BM6iU9xxJEAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df)"
      ],
      "metadata": {
        "id": "CKkF5D-AJybT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier"
      ],
      "metadata": {
        "id": "WxIDnG7jKKRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = DummyClassifier(strategy=\"most_frequent\")"
      ],
      "metadata": {
        "id": "zFN6NKHAKKlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline.fit(train.drop('sentiment', axis=1), train['sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "bNRfpubbKhs1",
        "outputId": "18cfeda8-2b93-4d9d-d10a-4b4fcb1cf5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyClassifier(strategy='most_frequent')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, log_loss"
      ],
      "metadata": {
        "id": "wUFJhwaqKvXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_predictions = baseline.predict(test.drop('sentiment', axis=1))\n",
        "baseline_accuracy = accuracy_score(test['sentiment'], baseline_predictions)"
      ],
      "metadata": {
        "id": "KdKPgH4SK2OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_f1score = f1_score(test['sentiment'], baseline_predictions)"
      ],
      "metadata": {
        "id": "l-1Jq4EVLfyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(predictions, actual):\n",
        "  accuracy = accuracy_score(actual, predictions)\n",
        "  f1 = f1_score(actual, predictions)\n",
        "  cross_entropy = log_loss(actual, predictions)\n",
        "  print(f\"Accuracy: {accuracy:.2f}\")\n",
        "  print(f\"F1 Score: {f1:.2f}\")\n",
        "  print(f\"Cross-Entropy: {cross_entropy:.2f}\")"
      ],
      "metadata": {
        "id": "xNLmW18oLnqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-- Baseline metrics --\")\n",
        "get_metrics(baseline_predictions, test['sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKZ_jYzTL6y1",
        "outputId": "d7a5f60d-e188-4c88-bdd8-69c2ceb62523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Baseline metrics --\n",
            "Accuracy: 0.78\n",
            "F1 Score: 0.88\n",
            "Cross-Entropy: 7.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "KEqjX_w7Oldc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "seed = 42\n",
        "\n",
        "def model_text(X, y, model, clf_model, desc):\n",
        "\n",
        "  X_c = model.fit_transform(X)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_c, y, random_state=seed)\n",
        "  clf = clf_model.fit(X_train, y_train)\n",
        "\n",
        "  # test accuracy\n",
        "  clf_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "  # f1 score\n",
        "  preds = clf.predict(X_test)\n",
        "  f1 = f1_score(y_test, preds)\n",
        "\n",
        "  # cross entropy\n",
        "  cross_entropy = log_loss(y_test, preds)\n",
        "\n",
        "  print(f'MODEL: {desc}')\n",
        "  print(f'test accuracy: {clf_accuracy:.2f}')\n",
        "  print(f'f1 score: {f1:.2f}')\n",
        "  print(f\"Cross-Entropy: {cross_entropy:.2f}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  return (clf_accuracy, f1)\n"
      ],
      "metadata": {
        "id": "dAciGn0PN3Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc = 'Logistic Regression (No regulaization, CountVectorizer)\\n'\n",
        "\n",
        "c = CountVectorizer()\n",
        "\n",
        "X = df['cleaned_text']\n",
        "y = df['sentiment'] # if score > 3 then sentiment=1, 0 otherwise\n",
        "\n",
        "clf_model = LogisticRegression(penalty=None)\n",
        "\n",
        "model_text(X, y, c, clf_model, desc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVXftHOnU8L-",
        "outputId": "587ab56d-ce86-45fb-bdb1-974941a86693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: Logistic Regression (No regulaization, CountVectorizer)\n",
            "\n",
            "test accuracy: 0.88\n",
            "f1 score: 0.92\n",
            "Cross-Entropy: 4.29\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8811048557353977, 0.9248927515614929)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desc = 'Logistic Regression (L2 Regularization, CountVectorizer)\\n'\n",
        "\n",
        "clf_model = LogisticRegression(penalty='l2')\n",
        "model_text(X, y, c, clf_model, desc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BFo3OAcYFvW",
        "outputId": "6f74071c-3e1d-4f7a-ef22-6a1639bb8723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: Logistic Regression (L2 Regularization, CountVectorizer)\n",
            "\n",
            "test accuracy: 0.89\n",
            "f1 score: 0.93\n",
            "Cross-Entropy: 4.10\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.886347642505278, 0.9288984767103989)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desc = 'Logistic Regression (L2 Regularization, TFIDF + n-gram)\\n'\n",
        "\n",
        "tfidf_n = TfidfVectorizer(ngram_range=(1,2),stop_words = 'english')\n",
        "clf_model = LogisticRegression()\n",
        "model_text(X, y, tfidf_n, clf_model, desc)"
      ],
      "metadata": {
        "id": "mMmm1GsNa-Ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfadbd60-0fb2-4a8a-8eae-f001e9c9d601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: Logistic Regression (L2 Regularization, TFIDF + n-gram)\n",
            "\n",
            "test accuracy: 0.88\n",
            "f1 score: 0.93\n",
            "Cross-Entropy: 4.22\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.882899366643209, 0.9290314325926559)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset shift, make positive-negative a 50-50 split\n",
        "\n",
        "def shift_negative_data(test_data):\n",
        "  negative_data = test_data[test_data['sentiment'] == 0]\n",
        "  negative_count = len(negative_data)\n",
        "  positive_data = test_data[test_data['sentiment'] == 1]\n",
        "  positive_sample = positive_data.sample(n=negative_count)\n",
        "  return positive_sample.append(negative_data)\n",
        "\n",
        "desc = 'Logistic Regression (L2 Regularization, CountVectorizer, dataset shift)\\n'\n",
        "\n",
        "c = CountVectorizer()\n",
        "\n",
        "X_c = df[['cleaned_text']]\n",
        "y = df['sentiment'] # if score > 3 then sentiment=1, 0 otherwise\n",
        "\n",
        "test_data = X_c.copy()\n",
        "test_data['sentiment'] = y\n",
        "\n",
        "test_data\n",
        "\n",
        "test_data = shift_negative_data(test_data)\n",
        "\n",
        "X_c_new = test_data['cleaned_text']\n",
        "y_new = test_data['sentiment']\n",
        "\n",
        "clf_model = LogisticRegression()\n",
        "\n",
        "model_text(X_c_new, y_new, c, clf_model, desc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIn5_EiNC9Cv",
        "outputId": "340793dc-7eda-41ac-d6af-1f753c939fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-39bdca20771e>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  return positive_sample.append(negative_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL: Logistic Regression (L2 Regularization, CountVectorizer, dataset shift)\n",
            "\n",
            "test accuracy: 0.84\n",
            "f1 score: 0.84\n",
            "Cross-Entropy: 5.82\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8386063275931117, 0.8400412796697627)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward Neural Network"
      ],
      "metadata": {
        "id": "yIMPQHt9LsiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "m8drMuCYBvXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FFNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim=40001, output_dim=2):\n",
        "    super(FFNN, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, 256) # 512\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(256, 32) # 128\n",
        "    self.dropout = nn.Dropout(p=0.7) # 0.8\n",
        "    self.dropout2 = nn.Dropout(p=0.7)\n",
        "    self.linear3 = nn.Linear(32, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.to(torch.float32)\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.linear2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "    output = self.linear3(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "8sxDiameBxwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf_n = TfidfVectorizer(ngram_range=(1,2),stop_words = 'english')\n",
        "df_sample = df.sample(frac=0.8)\n",
        "X_c = df_sample['cleaned_text']\n",
        "cv = CountVectorizer()\n",
        "\n",
        "vec_X = cv.fit_transform(X_c)\n",
        "y = np.array(df_sample['sentiment'].tolist())# if score > 3 then sentiment=1, 0 otherwise\n",
        "vec_X_train, vec_X_test, y_train, y_test = train_test_split(vec_X, y, test_size=0.15)"
      ],
      "metadata": {
        "id": "bGxdI1w9Cerz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].describe()"
      ],
      "metadata": {
        "id": "o1k1IW1uIOUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1075aa3-027a-4251-e0d2-bcbb4e918b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    113678.000000\n",
              "mean          0.780344\n",
              "std           0.414015\n",
              "min           0.000000\n",
              "25%           1.000000\n",
              "50%           1.000000\n",
              "75%           1.000000\n",
              "max           1.000000\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FFNN(vec_X_train.shape[1])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "_kDslWcYEeLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "psuRQ2-OFLX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 8\n",
        "batch_size = 256\n",
        "num_batches = vec_X_train.shape[0] // batch_size\n",
        "\n",
        "prev_accuracy = 0\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    running_loss = 0.\n",
        "    correct, total = 0, 0 \n",
        "\n",
        "    for i in tqdm(range(num_batches)):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        text = torch.tensor(vec_X_train[start:end].toarray())\n",
        "        label = torch.tensor(y_train[start:end]).cuda()\n",
        "\n",
        "        # 1. Store the inputs and labels in the GPU\n",
        "        text = text.to(device)\n",
        "        label = label.to(device)\n",
        "        # 2. Get the model predictions\n",
        "        predictions = model(text)\n",
        "\n",
        "        # 3. Zero the gradients out\n",
        "        optimizer.zero_grad()\n",
        "        # 4. Get the loss\n",
        "        loss = criterion(predictions, label)\n",
        "\n",
        "        # 5. Calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # 6. Update the weights\n",
        "        optimizer.step()\n",
        "            \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        _, predicted = torch.max(predictions, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (predicted == label).sum().item()\n",
        "    curr_accuracy = float(correct) / float(total)\n",
        "    print(f\"Accuracy {curr_accuracy}\")\n",
        "    print(f\"Loss: {running_loss / total}\")\n",
        "\n",
        "    if abs(curr_accuracy - prev_accuracy) < 0.005:\n",
        "      print(\"Breaking early due to converging accuracy\")\n",
        "      break\n",
        "    prev_accuracy = curr_accuracy\n",
        "    running_loss = 0.0\n",
        "    \n",
        "        "
      ],
      "metadata": {
        "id": "erEfixLsCsUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad0a954-f68c-4f2d-fa16-151676ee3b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:39<00:00,  7.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8388314991694352\n",
            "Loss: 0.001498415106033405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:42<00:00,  7.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.8944793397009967\n",
            "Loss: 0.0010798531665661654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:37<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9113501868770764\n",
            "Loss: 0.0009242289187541337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:39<00:00,  7.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9287401370431894\n",
            "Loss: 0.0007769912216376105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:38<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9402901785714286\n",
            "Loss: 0.00065385428043794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:37<00:00,  7.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.949296615448505\n",
            "Loss: 0.0005681488369599269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:38<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9580694559800664\n",
            "Loss: 0.00048758583983593616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:38<00:00,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9625207641196013\n",
            "Loss: 0.0004314224217729055\n",
            "Breaking early due to converging accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3ITnu35qNQD",
        "outputId": "af17add3-928c-4352-a34e-0d8a4ad021aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN(\n",
              "  (linear1): Linear(in_features=49368, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear2): Linear(in_features=256, out_features=32, bias=True)\n",
              "  (dropout): Dropout(p=0.7, inplace=False)\n",
              "  (dropout2): Dropout(p=0.7, inplace=False)\n",
              "  (linear3): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model(torch.tensor(vec_X_test.toarray()).to(device))"
      ],
      "metadata": {
        "id": "m-h97B_wIhTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_predictions.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "R4gTNOcOCyKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(test_predictions, axis=1)"
      ],
      "metadata": {
        "id": "h0Kceo31FPk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_metrics(pred, y_test)"
      ],
      "metadata": {
        "id": "02V7XSwvTCd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b47edd-7169-4ccc-a6e4-27ed3e5fee9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.90\n",
            "F1 Score: 0.94\n",
            "Cross-Entropy: 3.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.sum()"
      ],
      "metadata": {
        "id": "m6YVk6y3nxVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3646c81e-ace8-4921-e575-91c259de4c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10668"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUYdp2WQxKeu",
        "outputId": "434a9d0e-412e-41f4-b9be-a8f904f13683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13642"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_zeros = (y_test == 0).sum()"
      ],
      "metadata": {
        "id": "xylfVYHWxNfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IfEeJIrxVuQ",
        "outputId": "7dd44b3d-53f4-4443-edf6-be705a62f26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2974"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# balance data\n",
        "num_ones = 0\n",
        "indexes_to_keep = []\n",
        "for i, val in enumerate(y_test):\n",
        "  if val == 0:\n",
        "    indexes_to_keep.append(i)\n",
        "  elif num_ones < num_zeros:\n",
        "    num_ones += 1\n",
        "    indexes_to_keep.append(i)"
      ],
      "metadata": {
        "id": "aFCdxmr-xWT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shifted_vec_X_test = vec_X_test[indexes_to_keep]\n",
        "shifted_y_test = y_test[indexes_to_keep]"
      ],
      "metadata": {
        "id": "arikKHclxrw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model(torch.tensor(shifted_vec_X_test.toarray()).to(device))"
      ],
      "metadata": {
        "id": "-_9zOtOgxu7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_predictions.cpu().detach().numpy()\n",
        "pred = np.argmax(test_predictions, axis=1)\n",
        "get_metrics(pred, shifted_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqOvxQn2yKYN",
        "outputId": "e7b4471d-4244-4b3d-8c09-a2c49a7cd0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.83\n",
            "F1 Score: 0.85\n",
            "Cross-Entropy: 6.02\n"
          ]
        }
      ]
    }
  ]
}